---
layout: post
title: "LAK26: Democratising Policy in the age of AI"
date: 2025-10-22
workshop_date: 2026-04-28
type: news
---

## Bridging Socio-Technical Divides For Adaptive Policy Making

### A half day workshop for the [LAK'26 Conference](https://url.au.m.mimecastprotect.com/s/_OGyCXLWMAfnyMgEmfVh0uWUyWA?domain=solaresearch.org)

Kirsty Kitto, Simon Knight, Kalervo Gulson, Christian M. Stracke, Barbara Wasson

## How can we navigate Disagreement?

We live in an age of socio-technical uncertainty exacerbated by societal disagreement about how to navigate it. The last 10 years have seen a profound set of issues emerging in our society at large which have impacted our approach to education. Topics recently navigated by policy makers include: how to utilise data for Learning Analytics (LA) and Artificial Intelligence (AI) tools; the rise of disinformation on the web and in social media; disagreements about how to respond to Covid-19; trust in AI and other technologies; and the emergence of GenAI and the controversies that it introduces about how to assure integrity of student authorship and learning. In each scenario, we see sets of stakeholders navigating disagreement about what policies we need to address a problem and the effectiveness of policies, in a contested space where any policy is difficult to operationalize. Furthermore, these complex socio-technical problems spaces often bring with them significant disagreements about what the problem even is, adding to the existing complexities and difficulties in policy making ([Fazelpour & Fleisher, 2025](https://url.au.m.mimecastprotect.com/s/whVqCYW8MBS3J6vV5F9iouxByVf?domain=dl.acm.org); [Kippin & Cairney, 2022](https://url.au.m.mimecastprotect.com/s/Po4WCZY1WDcMVowKzuysquBUA3h?domain=link.springer.com).

Nonetheless, policy must still be made, and over the decades a number of different methods have emerged to support people in navigating uncertainty about how we might develop technology and the policies that surround its use. However, these methods are often developed to support the challenges of developing policy, including for example: the ethical development of the technology; how we might learn when to trust and critically use it; legal and ethical frameworks about how technology should be designed, developed and used; and participatory approaches to stakeholder engagement and how it might be improved. A number of projects are currently underway that are attempting to improve this situation, and this workshop will bring together people interested in moving policy making about the use of Artificial Intelligence and Data Analysis (AIDA) in educational settings towards more adaptive and anticipatory models.


## Workshop Aims and details


This workshop seeks to advance our methods for supporting educational stakeholders to productively collaborate with AIDA experts to improve policymaking in times of significant uncertainty. We will work to construct and publicly release a toolkit of services and approaches that can be used by those trying to support policy making, and evaluation,around the use of AIDA in educational settings. This toolkit will help people to work across boundaries of disciplinary knowledge, stakeholder expertise, ethics and trust.

Starting with a rapid introduction to the various challenges faced by educational policy makers in a selection of geopolitical contexts, we will then explore and critique the pros and cons of methods for bringing multiple stakeholders from a wide variety of different backgrounds together into fruitful conversations around the use of AIDA in education. The workshop will focus upon extending a variety of toolkits and resources that are now available. We anticipate that participants will emerge from the workshop with new means for constructing fruitful consultative and participatory approaches with a broad range of stakeholders in complex educational policymaking environments. Some of the potential approaches that have started to arise in this space will be explored, and applied to a specific policy making problem:
- How can we assure that the human rights of students are protected given the rise of AIDA usage in education?

Approaches to be explored in this workshop will include:
- Algorithmic audits and other legal instruments
- Hybrid forums, public consultations, citizens' assemblies etc.
- Algorithm games and other forms of game based learning such as serious games that support critical cross-stakeholder engagement with complex problems (e.g. GenAI arcade, UK Exam Algorithm Game). ([Ali et al., 2023](https://url.au.m.mimecastprotect.com/s/sOPeC1WL9zSpDE0J8sYtXuVcgUa?domain=doi.org); [Gulson et al., 2021](https://url.au.m.mimecastprotect.com/s/s481C2xM9AUkJE457TMuqu57t7P?domain=theconversation.com); [Hao & Stray, 2019](https://url.au.m.mimecastprotect.com/s/ZKkMC3QN90SmJRPDZuYC6uQVQub?domain=technologyreview.com); [Swist et al., 2023](https://url.au.m.mimecastprotect.com/s/smhxC4QO9DSJQ7n4rfNFxu4gvfh?domain=doi.org); [Swist, Gulson, Knight, et al., 2024](https://url.au.m.mimecastprotect.com/s/SZ2tC5QPWES0QWzkAF4HOukiiJE?domain=doi.org); [Swist, Gulson, & Thompson, 2024](https://url.au.m.mimecastprotect.com/s/zMAIC6XQ07toAGgLXFjI4u541_5?domain=doi.org); [Thompson et al., 2023](https://url.au.m.mimecastprotect.com/s/SFX0C71RA7HmxW0GLurSDuoTJav?domain=doi.org)
- Tools and services for modelling educational scenarios and supporting counterfactual reasoning (e.g. graphical causal models, the whatif tool)

## Who should attend?

We seek participants who are interested in supporting the process of boundary crossing between one (or more) of the following general perspectives:
- Policy makers: Those attempting to develop policy to respond to the new wave of AI that is impacting education
- AIDA developers: Those building tools, new algorithmic approaches, and other technological solutions that satisfy legal, ethical and other Responsible Research and Innovation (RRI) principles.
- Education stakeholders: Those attempting to engage with people developing policies or tools about AIDA and its use in education (e.g. student, teacher, parent), but who are often not included in policy discussions or decisions.



